\addvspace {10\p@ }
\contentsline {figure}{\numberline {1.1}{\ignorespaces Scatter plots showing the relation between the ratio of error (in x-axis of the centroid poistions) to the CRLB and the signal-to-noise ratio of stars. Errors are found from fitting the exact PSF model to the stars, with FWHM of : 2 (upper left), 2.8 (upper right), 4 (lower left), and 5.6 (lower right) pixels. In each scatter plot, the blue solid line represents the ratio of the root-mean-squared-error to the CRLB, and the red line represents the ratio achievable by an optimal estimator.}}{43}{figure.1.1}
\contentsline {figure}{\numberline {1.2}{\ignorespaces Scatter plots showing the relation between the ratio of error (in x-axis of the centroid poistions) to the CRLB and the signal-to-noise ratio of stars. Errors are found from applying the matched filter polynomial centroiding to the stars, with FWHM of : 2 (upper left), 2.8 (upper right), 4 (lower left), and 5.6 (lower right) pixels. In each scatter plot, the blue solid line represents the ratio of the root-mean-squared-error to the CRLB, and the red line represents the ratio achievable by an optimal estimator.}}{44}{figure.1.2}
\contentsline {figure}{\numberline {1.3}{\ignorespaces Scatter plots showing the relation between the ratio of error (in x-axis of the centroid poistions) to the CRLB and the signal-to-noise ratio of stars. Errors are found from applying the fixed-Gaussian polynomial centroiding to the stars, with FWHM of : 2 (upper left), 2.8 (upper right), 4 (lower left), and 5.6 (lower right) pixels. In each scatter plot, the blue solid line represents the ratio of the root-mean-squared-error to the CRLB, and the red line represents the ratio achievable by an optimal estimator.}}{45}{figure.1.3}
\contentsline {figure}{\numberline {1.4}{\ignorespaces Scatter plots showing the relation between the ratio of error (in x-axis of the centroid poistions) to the CRLB and the signal-to-noise ratio of stars. Errors are found from applying the 7$\times $7 moment method to the stars, with FWHM of : 2 (upper left), 2.8 (upper right), 4 (lower left), and 5.6 (lower right) pixels. In each scatter plot, the blue solid line represents the ratio of the root-mean-squared-error to the CRLB, and the red line represents the ratio achievable by an optimal estimator.}}{46}{figure.1.4}
\contentsline {figure}{\numberline {1.5}{\ignorespaces Scatter plots showing the relation between the ratio of error (in x-axis of the centroid poistions) to the CRLB and the FWHM of stars. Errors are found from fitting the exact PSF model to the stars, with SNR of : 5 (upper left), 10 (upper right), 20 (lower left), and 40 (lower right). In each scatter plot, the blue solid line represents the ratio of the root-mean-squared-error to the CRLB, and the red line represents the ratio achievable by an optimal estimator.}}{47}{figure.1.5}
\contentsline {figure}{\numberline {1.6}{\ignorespaces Scatter plots showing the relation between the ratio of error (in x-axis of the centroid poistions) to the CRLB and the FWHM of stars. Errors are found from applying the matched filter polynomial centroiding to the stars, with SNR of : 5 (upper left), 10 (upper right), 20 (lower left), and 40 (lower right). In each scatter plot, the blue solid line represents the ratio of the root-mean-squared-error to the CRLB, and the red line represents the ratio achievable by an optimal estimator.}}{48}{figure.1.6}
\contentsline {figure}{\numberline {1.7}{\ignorespaces Scatter plots showing the relation between the ratio of error (in x-axis of the centroid poistions) to the CRLB and the FWHM of stars. Errors are found from applying the fixed-Gaussian polynomial centroiding to the stars, with SNR of : 5 (upper left), 10 (upper right), 20 (lower left), and 40 (lower right). In each scatter plot, the blue solid line represents the ratio of the root-mean-squared-error to the CRLB, and the red line represents the ratio achievable by an optimal estimator.}}{49}{figure.1.7}
\contentsline {figure}{\numberline {1.8}{\ignorespaces Scatter plots showing the relation between the ratio of error (in x-axis of the centroid poistions) to the CRLB and the FWHM of stars. Errors are found from applying the 7$\times $7 moment method to the stars, with SNR of : 5 (upper left), 10 (upper right), 20 (lower left), and 40 (lower right). In each scatter plot, the blue solid line represents the ratio of the root-mean-squared-error to the CRLB, and the red line represents the ratio achievable by an optimal estimator.}}{50}{figure.1.8}
\addvspace {10\p@ }
\contentsline {figure}{\numberline {2.1}{\ignorespaces The two-point correlation function $\xi _{\mathrm {gg}}(r)$ (left) and group multiplicity function $g(N)(N)$ (right) summary statistics of the mock observations generated from the ``true'' HOD parameters described in Section \ref {sec:mock_obv}. The width of the shaded region corresponds to the square root of the covariance matrix diagonal elements (Eq. \ref {eq:cov}). In our ABC analysis, we treat the $\xi _{\mathrm {gg}}(r)$ and $g(N)(N)$ above as the summary statistics of the observation.}}{66}{figure.2.1}
\contentsline {figure}{\numberline {2.2}{\ignorespaces We demonstrate the evolution of the ABC particles, $\mathaccentV {vec}17E{\theta }_t$, over iterations $t = 1$ to $9$ in the $\qopname \relax o{log}\mathcal {M}_{min}$ and $\qopname \relax o{log}\mathcal {M}_1$ parameter space. $\mathaccentV {bar}016{n}$ and $g(N)(N)$ are used as observables for the above results. For reference, in each panel, we include the ``true'' HOD parameters (black star) listed in Section \ref {sec:mock_obv}. The initial distance threshold, $\mathaccentV {vec}17E\epsilon _1 = [\infty , \infty ]$ at $t=1$ (top left) so the $\mathaccentV {vec}17E{\theta }_1$ spans the entire range of the prior distribution, which is also the range of the panels. We see for $t < 5$, the parameter space occupied by the ABC $\mathaccentV {vec}17E{\theta }_t$ shrinks dramatically. Eventually when the algorithm converges, $t > 7$, the parameter space occupied by $\mathaccentV {vec}17E{\theta }_t$ no longer shrinks and their distributions represent the posterior distribution of the parameters. At $t=9$, the final iteration, the ABC algorithm has converged and we find that $\mathaccentV {vec}17E{\theta }_\mathrm {true}$ lies safely within the $68\%$ confidence region.}}{67}{figure.2.2}
\contentsline {figure}{\numberline {2.3}{\ignorespaces We illustrate the convergence of the ABC algorithm through the evolution of the ABC particle distribution as a function of iteration for parameters $\qopname \relax o{log}\mathcal {M}_\mathrm {min}$ (left), $\alpha $ (center), and $\qopname \relax o{log}\mathcal {M}_1$ (right). The top panel corresponds our ABC results using the observables $(\mathaccentV {bar}016{n}, g(N)(N))$, while the lower panel plots corresponds to the ABC results using $(\mathaccentV {bar}016{n}, \xi _{\mathrm {gg}}(r))$. The distributions of parameters show no significant change after $t > 7$, which suggests that the ABC algorithm has converged.}}{70}{figure.2.3}
\contentsline {figure}{\numberline {2.4}{\ignorespaces We present the constraints on the \citet {zheng07} HOD model parameters obtained from our ABC-PMC analysis using $\mathaccentV {bar}016{n}$ and $\xi _{\mathrm {gg}}(r)$ as observables. The diagonal panels plot the posterior distribution of each HOD parameter with vertical dashed lines marking the $50\%$ quantile and $68\%$ confidence intervals of the distribution. The off-diagonal panels plot the degeneracies between parameter pairs. The range of each panel corresponds to the range of our prior choice. The ``true'' HOD parameters, listed in Section \ref {sec:mock_obv}, are also plotted in each of the panels (black). For $\qopname \relax o{log}\mathcal {M}_0$, $\alpha $, and $\sigma _{\qopname \relax o{log}M}$, the ``true'' parameter values lie near the center of the $68\%$ confidence interval of the posterior distribution. For $\qopname \relax o{log}\mathcal {M}_1$ and $\qopname \relax o{log}\mathcal {M}_\mathrm {min}$, which have tight constraints, the ``true'' values lie within the $68\%$ confidence interval. Ultimately, the ABC parameter constraints we obtain in our analysis are consistent with the ``true'' HOD parameters.}}{83}{figure.2.4}
\contentsline {figure}{\numberline {2.5}{\ignorespaces Same as Figure \ref {fig:abc_corner_nbarxi} but for our ABC analysis using $\mathaccentV {bar}016{n}$ and $g(N)(N)$ as observables. The ABC parameter constraints we obtain are consistent with the ``true'' HOD parameters.}}{84}{figure.2.5}
\contentsline {figure}{\numberline {2.6}{\ignorespaces We compare the ABC-PMC posterior prediction for the observables $\xi _{\mathrm {gg}}(r)$ (left) and $g(N)(N)$ (right) (orange; Section \ref {sec:abc_results}) to $\xi _{\mathrm {gg}}(r)$ and $g(N)(N)$ of the mock observation (black) in the top panels. In the lower panels, we plot the ratio between the ABC-PMC posterior predictions for $\xi _{\mathrm {gg}}$ and $g(N)$ to the mock observation $\xi _{\mathrm {gg}}^\mathrm {obvs}$ and $g(N)^\mathrm {obvs}$. The darker and lighter shaded regions represent the $68\%$ and $95\%$ confidence regions of the posterior predictions, respectively. The error-bars represent the square root of the diagonal elements of the error covariance matrix (equation \ref {eq:cov}) of the mock observations. Overall, the observables drawn from the ABC-PMC posteriors are in good agreement with $\xi _{\mathrm {gg}}$ and $g(N)$ of the mock observations. The lower panels demonstrate that for both observables, the error-bars of the mock observations lie within the $68\%$ confidence interval of the ABC-PMC posterior predictions.}}{85}{figure.2.6}
\contentsline {figure}{\numberline {2.7}{\ignorespaces We compare the $\qopname \relax o{log}\mathcal {M}_{\rm min}$, $\alpha $, and $\qopname \relax o{log}\mathcal {M}_{1}$ parameter constraints from ABC-PMC (orange) to constraints from the Gaussian pseudo-ikelihood MCMC (blue) using $\mathaccentV {bar}016{n}_{\mathrm {g}}$ and $\xi _{\mathrm {gg}}(r)$ as observables. The \emph {top} panels compares the two methods' marginalized posterior PDFs over the parameters. In the \emph {bottom} panels, we include box plots marking the confidence intervals of the posterior distributions. The boxes represent the $68\%$ confidence interval while the ``whiskers'' represent the $95\%$ confidence interval. We mark the ``true'' HOD parameters with vertical black dashed line. The marginalized posterior PDFs obtained from the two methods are consistent with each other. The ABC-PMC and Gaussian pseudo-likelihood constraints are generally consistent for $\qopname \relax o{log}\mathcal {M}_{\rm min}$ and $\qopname \relax o{log}\mathcal {M}_{1}$. The ABC-PMC constraint for $\alpha $ is slightly less biased and has slightly larger uncertainty then the constraint from Gaussian pseudo-likelihood analysis.}}{86}{figure.2.7}
\contentsline {figure}{\numberline {2.8}{\ignorespaces Same as Figure \ref {fig:hist_nbarxi}, but both the ABC-PMC analysis and the Gaussian pseudo-likelihood MCMC analysis use $\mathaccentV {bar}016{n}_{\mathrm {g}}$ and $g(N)(N)$ as observables. Both methods derive constraints consistent with the ``true'' HOD parameters and infer the region of allowed values to similar precision. We note that the MCMC constraint on $\alpha $ is slightly more biased compared to ABC-PMC estimate. This discrepancy may stem from the fact that the use of Gaussian pseudo-likelihood and its associated assumptions is more spurious when modeling the group multiplicity function.}}{87}{figure.2.8}
\contentsline {figure}{\numberline {2.9}{\ignorespaces We compare the ABC-PMC (orange) and the Gaussian pseudo-likelihood MCMC (blue) predictions of the 68\% and 95\% posterior confidence regions over the HOD parameters ($\qopname \relax o{log}\mathcal {M}_{\rm min}$, $\alpha $, and $\qopname \relax o{log}\mathcal {M}_{1}$) using $\mathaccentV {bar}016{n}_{\mathrm {g}}$ and $\xi _{\mathrm {gg}}(r)$ as observables. In each panel, the black star represents the ``true'' HOD parameters used to generate the mock observations. Both inference methods derive confidence regions consistent with the ``true'' HOD parameters.}}{88}{figure.2.9}
\contentsline {figure}{\numberline {2.10}{\ignorespaces Same as Figure \ref {fig:cont_nbarxi}, but using $\mathaccentV {bar}016{n}_{\mathrm {g}}$ and $g(N)(N)$ as observables. Again, the confidence regions derived from both methods are consistent with the ``true'' HOD parameters used to generate the mock observations. The confidence region of $\alpha $ from the Gaussian pseudo-likelood method is biased compared to the ABC-PMC contours. This may be due to the fact that the true likelihood function that describes $g(N)(N)$ deviates significantly from the assumed Gaussian functional form.}}{88}{figure.2.10}
\addvspace {10\p@ }
\contentsline {figure}{\numberline {3.1}{\ignorespaces Constraints on the central assembly bias $\mathcal {A}_{\rm cen}$ (Top panel) and the satellite assembly bias $\mathcal {A}_{\rm sat}$ (Bottom panel) parameters. The $\mathcal {A}_{\rm cen}$ constraints for the $M_{\rm r} < -20.5, -20, -19.5$ samples favor positive values of $\mathcal {A}_{\rm cen}$ with the tightest constraint coming from the $M_{\rm r} < -20$ sample. The $\mathcal {A}_{\rm cen}$ constraints for the $M_{\rm r}<-18$ sample favor negative values of $\mathcal {A}_{\rm cen}$. All the $\mathcal {A}_{\rm sat}$ constraints are consistent with no satellite assembly bias.}}{122}{figure.3.1}
\contentsline {figure}{\numberline {3.2}{\ignorespaces Comparison between the posterior predictions of $w_{p}(r_{p})$ and the SDSS $w_{p}(r_{p}$ measurements. Predictions from the standard HOD model (HOD model with assembly bias) are shown in red (blue). The Dark and light shaded regions mark the 68$\%$ and the 95$\%$ confidence intervals. The errorbars are from the diagonal elements of the covariance matrix.}}{123}{figure.3.2}
\contentsline {figure}{\numberline {3.3}{\ignorespaces Same as Figure \ref {fig:wpmodel}, but showing the fractional difference between the posterior predictions and the observed projected 2PCF for all the luminosity threshold samples. In all luminosity threshold samples, predictions of the two models for small scale clustering are consistent. In the samples that favor more positive values of the central assembly bias parameter ($M_{\rm r}<-19.5,-19,-20,-20.5$), modeling of the intermediate and large scale clustering is slightly improved. The large scale clustering modeling of the $M_{\rm r}<-18$ sample is also improved because of negative constraints on $\mathcal {A}_{\rm cen}$ which is equivalent to allocation of more central galaxies in low concentration halos at fixed halo mass.}}{124}{figure.3.3}
\contentsline {figure}{\numberline {3.4}{\ignorespaces Demonstration of the relative difference in $w_{p}$ between randomized and non-randomized catalogs for different luminosity threshold samples: $M_{\mathrm r}<-20,-20.5,-21$. The errorbars are from the diagonal elements of the covariance matrix. The blue lines correspond to the random draws from the posterior probability (summarized in Table \ref {tab:constraints}) over the parameters of the HOD model with assembly bias. The red line corresponds to the subhalo abundance matching catalog (\citealt {hw2013,hearin2014}). Our constraints favor \emph {more} \emph {moderate} levels of the impact of assembly bias on galaxy clustering than the levels seen in the abundance matching mock catalogs. Within both models, the small scale clustering remains unaltered after randomizing the catalogs, signaling the lack of correlation between the satellite occupation and the halo concentration at a fixed mass in the two models.}}{125}{figure.3.4}
\contentsline {figure}{\numberline {3.5}{\ignorespaces Difference in the information criteria between the HOD model with assembly bias and the model without assembly bias. $\bf {Top}$: $\Delta $BIC = BIC(with assembly bias) - BIC(without assembly bias). $\bf {Bottom}$: $\Delta $AIC = AIC(with assembly bias) - AIC(without assembly bias). According to BIC (AIC), the more complex model with assembly bias is favored once $\Delta $BIC$<0$ ($\Delta $AIC$<0$). Both $\Delta $BIC and $\Delta $AIC are lower for the samples with tighter constraints over the central assembly bias parameter $\mathcal {A}_{\rm cen}$, with $\Delta $BIC being (marginally) negative only for $M_{\rm r}<-20,-18$ samples that yield strongest constraints on $\mathcal {A}_{\rm cen}$.}}{126}{figure.3.5}
\contentsline {figure}{\numberline {3.6}{\ignorespaces Comparison between the constraints on the assembly bias parameters $\mathcal {A}_{\rm cen}$ (shown in the top panel) and $\mathcal {A}_{\rm sat}$ (shown in the bottom panel) for different simulations: $\mathtt {SMDP}$ (shown with circle), and $\mathtt {BolshoiP}$ (shown with cross). The errorbars mark the 68$\%$ uncertainty over the parameters. Shaded blue regions show the upper and lower bounds reported by \citet {zentner2016} that uses the $\mathtt {BolshoiP}$ and clustering measurements of \citet {zehavi2011}. For the confidence intervals corresponding to the shaded blue regions, we refer the readers to Table 2 of \citet {zentner2016}. The central assembly bias constraints found from the two simulations are consistent, with the constraints for from the $\mathtt {SMDP}$ simulation being tighter for the most luminous samples. The constraints on $\mathcal {A}_{\rm sat}$ from the two simulations are largely in agreement with the exception of $M_{\rm r}<-19 ,\tmspace +\thickmuskip {.2777em} -20.5$ samples that favor more positive values of $\mathcal {A}_{\rm sat}$ when the $\mathtt {BolshoiP}$ simulation is used.}}{127}{figure.3.6}
\contentsline {figure}{\numberline {3.7}{\ignorespaces Constraints over the satellite assembly bias parameters from luminosity-threshold samples $M_{\rm r}<-19 ,\tmspace +\thickmuskip {.2777em} -20.5$, for two different simulations: $\mathtt {BolshoiP}$ (yellow), and $\mathtt {SMDPL}$ (green). The $\mathcal {A}_{\rm sat}$ constraints found using the $\mathtt {BolshoiP}$ simulation favor more positive values of $\mathcal {A}_{\rm sat}$, while the constraints found using the $\mathtt {SMDP}$ simulation favor zero satellite assembly bias.}}{128}{figure.3.7}
\contentsline {figure}{\numberline {3.8}{\ignorespaces An example of posterior probability distribution over the parameters of the standard HOD model with no assembly bias (shown with yellow), and the HOD model with assembly bias (shown in blue). These constraints are obtained from the clustering measurements of the $M_{\rm r} < -20.5$ luminosity threshold sample. The dark (light) blue shaded regions show the 68$\%$ (95 $\%$) confidence intervals. The constraints on $\mathcal {A}_{\rm cen}$ and $\mathcal {A}_{\rm sat}$ show positive correlation between the central occupation and the halo concentration at fixed halo mass, and lack of correlation between the satellite occupation and halo concentration at fixed halo mass.}}{129}{figure.3.8}
\addvspace {10\p@ }
\contentsline {figure}{\numberline {4.1}{\ignorespaces Dark matter overdensity $\delta = \rho _{\rm m}/\rho -1$ slices of 20 $\tmspace +\thinmuskip {.1667em}h^{-1}\tmspace +\thinmuskip {.1667em}{\rm Mpc}$ from the high-resolution BigMultiDark simulation (left panels) , the low-resolution \textsc {FastPM} simulation (central panels) and from the \textsc {alpt} simulation (right panels), taking a subvolume of $(1250 \tmspace +\thickmuskip {.2777em}\tmspace +\thinmuskip {.1667em}h^{-1}\tmspace +\thinmuskip {.1667em}{\rm Mpc})^3$ (top panels), $(625 \tmspace +\thickmuskip {.2777em}\tmspace +\thinmuskip {.1667em}h^{-1}\tmspace +\thinmuskip {.1667em}{\rm Mpc})^3$ (middle panels), and $(312.5 \tmspace +\thickmuskip {.2777em}\tmspace +\thinmuskip {.1667em}h^{-1}\tmspace +\thinmuskip {.1667em}{\rm Mpc})^3$ (bottom panels). The structures in the high-resolution $N$-body simulation and the low-resolution \textsc {FastPM} simulation look very similar inspite of having very different resolutions ($3840^3$ vs $960^3$ particles). The low-resolution \textsc {alpt} simulation looks more diffuse.}}{152}{figure.4.1}
\contentsline {figure}{\numberline {4.2}{\ignorespaces Posterior probability distribution of the \textsc {patchy} bias parameters $\{\delta _{\rm th},\alpha ,\beta ,\rho _{\epsilon },\epsilon \}$. The contours mark the 68$\%$ and the 95$\%$ confidence intervals of the posterior probabilities. This plot is made using the open-source software \textsc {corner} (\citealt {corner}).}}{153}{figure.4.2}
\contentsline {figure}{\numberline {4.3}{\ignorespaces Top: Demonstration of the halo bivariate probability distribution function of halos (halo counts-in-cells) in the BigMultiDark simulation (shown in black) and in the \textsc {FastPM}-\textsc {patchy} simulation (shown in blue) and in the \textsc {alpt}-\textsc {patchy} simulation (shown in red) on the left. Comparison between the real-space power spectrum of the BDM halos (shown in black) in the reference BigMultiDark simulation and that of the halos in the \textsc {FastPM}-\textsc {patchy} (\textsc {alpt}-\textsc {patchy}) simulation shown in blue (red) on the right. Bottom: Ratio between the halo PDFs of the approximate mocks and halo PDF of the BigMultiDark simulation on the left. Ratio between the halo power spectra of the approximate mocks and the halo power spectrum of the BigMultiDark simulation on the right.}}{154}{figure.4.3}
\contentsline {figure}{\numberline {4.4}{\ignorespaces Real-space bispectrum of the BigMD BDM halos and that of the approximate mocks as a function of angle $\alpha _{12}$ between $\mathbf {k}_1$ and $\mathbf {k}_{2}$ for $k_{1}=k_{2}=0.1\tmspace +\thickmuskip {.2777em} \tmspace +\thinmuskip {.1667em}h\tmspace +\thinmuskip {.1667em}{\rm Mpc}^{-1}$ (upper left), $2k_{1}=k_{2}=0.2\tmspace +\thickmuskip {.2777em} \tmspace +\thinmuskip {.1667em}h\tmspace +\thinmuskip {.1667em}{\rm Mpc}^{-1}$ (upper right), $k_{1}=k_{2}=0.15\tmspace +\thickmuskip {.2777em} \tmspace +\thinmuskip {.1667em}h\tmspace +\thinmuskip {.1667em}{\rm Mpc}^{-1}$ (middle left), $k_{1}=k_{2}=0.2\tmspace +\thickmuskip {.2777em} \tmspace +\thinmuskip {.1667em}h\tmspace +\thinmuskip {.1667em}{\rm Mpc}^{-1}$ (middle right), $2k_{1}=k_{2}=0.3\tmspace +\thickmuskip {.2777em} \tmspace +\thinmuskip {.1667em}h\tmspace +\thinmuskip {.1667em}{\rm Mpc}^{-1}$ (lower left), and $2k_{1}=k_{2}=0.4\tmspace +\thickmuskip {.2777em} \tmspace +\thinmuskip {.1667em}h\tmspace +\thinmuskip {.1667em}{\rm Mpc}^{-1}$ (lower right). The BigMD is represent by the solid black line, while \textsc {alpt}-\textsc {patchy} is represented by the dashed red line, and \textsc {FastPM}-\textsc {patchy} is represented by the dashed blue line.}}{155}{figure.4.4}
\addvspace {10\p@ }
\contentsline {figure}{\numberline {5.1}{\ignorespaces Left: Demonstration of the initialization of the super-resolution PSF model. The initial PSF was constructed by scaling (background subtraction and flux normalization), shifting (through matched-filter polynomial centroiding), upsampling (with cubic spline interpolation), and averaging the isolated stars in the observation sample. Right: Super-resolution PSF estimated by optimizing the likelihood function after six iterations. We note that the averaged upsampled initial PSF is smooth and lacks the sharp features visible across the full radian support of the PSF, specially the tails.}}{172}{figure.5.1}
\contentsline {figure}{\numberline {5.2}{\ignorespaces An example of a patch containing a high signal-to-noise ratio star in the training set. Upper-left and upper-right panels show the data and the model respectively. The lower left panel shows $\chi $. The lower right panel shows the flagged pixels. Pixels with $\mathtt {FLAG}=0$ are used in PSF-fitting. Pixels with are $\mathtt {FLAG}=1$ (provided by the MAST data) are masked out prior to the analysis. Finally, pixels with $\mathtt {FLAG}=2$ correspond to the pixels in a given model realization with $\chi ^{2}_{\rm clip} > 3$.}}{173}{figure.5.2}
\contentsline {figure}{\numberline {5.3}{\ignorespaces Same as Figure\nobreakspace {}\ref {fig:training_1} but showing a different high signal-to-noise ratio star in the training set.}}{174}{figure.5.3}
\contentsline {figure}{\numberline {5.4}{\ignorespaces Same as Figure\nobreakspace {}\ref {fig:training_1} but showing a low signal-to-noise ratio star in the training set.}}{175}{figure.5.4}
\contentsline {figure}{\numberline {5.5}{\ignorespaces Same as Figure\nobreakspace {}\ref {fig:training_1} but showing a different low signal-to-noise ratio star in the training set.}}{176}{figure.5.5}
\contentsline {figure}{\numberline {5.6}{\ignorespaces An example of a patch in the validation set containing multiple point sources. Upper-left and upper-right panels show the data and the model respectively. The lower left panel shows the $\chi $ map. The lower right panel shows the flagged pixels. Pixels with $\mathtt {FLAG}=0$ are used in PSF-fitting. Pixels with $\mathtt {FLAG}=1$ (provided by the MAST data) are masked out prior to the analysis. Finally, pixels with $\mathtt {FLAG}=2$ correspond to the pixels in a given model realization with $\chi ^{2}_{\rm clip} > 3$. In the lower left panel, pixels with $\chi ^{2}_{\rm clip} > 3$ are masked out from the $\chi $ map. Note that the point sources visible in the lower right and upper right corner of the data are masked out in the $\chi $ map. Here we do not grow the masked regions and therefore a small fraction of the light from the other point sources still contribute to the map.}}{177}{figure.5.6}
\contentsline {figure}{\numberline {5.7}{\ignorespaces Same as Figure\nobreakspace {}\ref {fig:validation_1} but showing a different patch of sky.}}{178}{figure.5.7}
\contentsline {figure}{\numberline {5.8}{\ignorespaces Same as Figure\nobreakspace {}\ref {fig:validation_1} but showing a different patch of sky. Two nearly overlapping faint point sources are present in this patch. The clipping algorithm masks out the second star. Since we do not grow the masking regions in this example, it is likely that the second faint star could still have slight contribution to the $\chi $ map.}}{179}{figure.5.8}
\contentsline {figure}{\numberline {5.9}{\ignorespaces Same as Figure\nobreakspace {}\ref {fig:validation_1} but showing a different patch of the sky and and a PSF diffraction spike from a nearby source whose centroid is not in the patch. The clipping algorithm masks out most of the pixels that are affected by the PSF tail from an external source. Once again, this demonstrates the need to adopt the more conservative masking algorithm that grows the clipped regions in every direction.}}{180}{figure.5.9}
\contentsline {figure}{\numberline {5.10}{\ignorespaces Same as Figure\nobreakspace {}\ref {fig:validation_1} but showing a different patch of sky and a more \emph {conservative} clipping algorithm. Masked regions containing the pixels with $\chi ^{2}_{\rm clip} > 3$ are grown in every direction with one pixel.}}{181}{figure.5.10}
\contentsline {figure}{\numberline {5.11}{\ignorespaces Same as Figure\nobreakspace {}\ref {fig:validation_5} but showing a different patch of sky. The more \emph {conservative} clipping algorithm masks out pixels that are ill-fit given the downsampled PSF model given by Eq.\nobreakspace {}\ref {eq:model}.}}{182}{figure.5.11}
\contentsline {figure}{\numberline {5.12}{\ignorespaces Same as Figure\nobreakspace {}\ref {fig:validation_5} but showing a different patch of sky. Note that the pixels along the lower tails of the PSF receive light contribution from other point sources and are masked out in the $\chi $-map.}}{183}{figure.5.12}
